{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8a5089",
   "metadata": {},
   "source": [
    "## ERA V7 \n",
    "\n",
    "- All from V6 \n",
    "- Added elevation\n",
    "- Added total precipitation\n",
    "- Used to create static images of hardiness zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073396dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import goes here \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import HeatMap, HeatMapWithTime, TimeSliderChoropleth\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import shapely as shp\n",
    "import requests\n",
    "import contextily as ctx\n",
    "import cfgrib\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap, BoundaryNorm\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba60169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def get_hardiness_zones(ds, boundary, temp_range=[-26, 40], precipitation_range=[0, 3000], months=list(range(1,13)), years=[1950, 2025], end_month=\"DEC\", yearly_mean=True): \n",
    "    \"\"\"\n",
    "    Get filtered temperature data. \n",
    "    \"\"\"\n",
    "    # Filter Date\n",
    "    ds_africa = ds.sel(time=slice(f\"{years[0]}-01-01\", f\"{years[1]}-12-31\"))\n",
    "    ds_africa = ds_africa.where((precipitation_range[0] <= ds.tp) & (ds.tp <= precipitation_range[1]))\n",
    "\n",
    "    # Filter Specific months \n",
    "    ds_africa = ds_africa.sel(time=ds_africa.time.dt.month.isin(months))\n",
    "\n",
    "    # Get the yearly mean\n",
    "    if yearly_mean:\n",
    "        ds_africa = ds_africa.assign_coords(year=ds_africa.time.to_index().to_period(f\"Y-{end_month}\"))\n",
    "        ds_africa = ds_africa.groupby(\"year\").mean(dim=\"time\", skipna=True)\n",
    "\n",
    "    africa_df = ds_africa.to_dataframe().reset_index()\n",
    "    africa_df[\"time\"] = gpd.pd.to_datetime(africa_df[\"year\"].astype(str), format=\"%Y\")\n",
    " \n",
    "    africa_df = africa_df[[\"time\", \"t2m\", \"tp\", \"latitude\", \"longitude\"]]\n",
    "\n",
    "    africa_df.dropna(inplace=True)\n",
    "    africa_df.reset_index(drop=True, inplace=True)\n",
    "    africa_df = africa_df.round(6)\n",
    "    geometry = gpd.points_from_xy(africa_df.longitude, africa_df.latitude)\n",
    "    africa_df = gpd.GeoDataFrame(africa_df, geometry=geometry, crs=\"EPSG:4326\") # , crs=\"EPSG:4326\"\n",
    "\n",
    "    # Select points within the boundary\n",
    "    geo_df = africa_df.loc[africa_df[\"geometry\"].within(boundary)]\n",
    "    print(\"Total points within boundary:\", len(geo_df))\n",
    "    \n",
    "    # # Filter temperature range\n",
    "    geo_df.loc[:, \"zones\"] = np.where(((temp_range[0] <= geo_df.t2m) & (geo_df.t2m <= temp_range[1])), 1, 0)\n",
    "    geo_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Total points within temperature range:\", len(geo_df[geo_df[\"zones\"] == 1]))\n",
    "\n",
    "    return geo_df\n",
    "\n",
    "\n",
    "def get_boundaries(boundary, countries): \n",
    "    \"\"\"Give a set of boundaries filter and return a union of the geometries within the given countries.\"\"\"\n",
    "\n",
    "    boundary = boundary[boundary[\"ADMIN\"].isin(countries)][\"geometry\"]  # \"ADMIN\"\n",
    "    return boundary\n",
    "\n",
    "# Clustering \n",
    "def cluster_temperature_data(df, eps=0.15, hull_ratio=0.3): \n",
    "    \"\"\"Cluster points into an area to remove points within it.\"\"\"\n",
    "    hulls = []\n",
    "    times = df[\"time\"].dt.year.unique()\n",
    "    for t in times: \n",
    "        #print(t)\n",
    "        df_temp = df[df[\"time\"].dt.year == t]\n",
    "        coords = df_temp[[\"longitude\", \"latitude\"]].values\n",
    "        db = DBSCAN(eps=eps, min_samples=2).fit(coords)\n",
    "        labels = db.labels_\n",
    "\n",
    "        # Create convex hull\n",
    "        for l in np.unique(labels):\n",
    "            if l == -1: \n",
    "                continue\n",
    "            cluster_points = coords[labels == l]\n",
    "            multipoint = shp.MultiPoint(cluster_points)\n",
    "            hull = shp.concave_hull(multipoint, ratio=hull_ratio, allow_holes=True)\n",
    "            hulls.append({\"time\": t, \"geometry\": hull})\n",
    "\n",
    "    return hulls\n",
    "\n",
    "\n",
    "def split_dataframe(df, split_size):\n",
    "    \"\"\"\n",
    "    Split a dataframe into smaller chunks for elevation API requests.\n",
    "    \"\"\"\n",
    "    \n",
    "    splits = []\n",
    "    for start in range(0, len(df), split_size):\n",
    "        end = start + split_size\n",
    "        chunk = df.iloc[start:end].to_dict(orient=\"records\")\n",
    "        splits.append({\"locations\": chunk})\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3ab33",
   "metadata": {},
   "source": [
    "### Load and filter temperature data for hardiness zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9421e9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ERA5 data...\n"
     ]
    }
   ],
   "source": [
    "# Read datasets\n",
    "print(\"Loading ERA5 data...\")\n",
    "# ds = xr.load_dataset(\"./dataset/africa_t2m.grib\", engine=\"cfgrib\", decode_timedelta=True) # \"./dataset/africa_t2m.grib\"\\\n",
    "ds = cfgrib.open_datasets(\"./dataset/t2m_tp.grib\")\n",
    "ds_t2m ,ds_tp = ds[0], ds[2]\n",
    "ds_t2m = ds_t2m - 273.15 # Convert from Kelvin to Celsius\n",
    "\n",
    "# Convert precipitation from m to mm\n",
    "# See ERA5 monthly averaged reanalysis https://confluence.ecmwf.int/pages/viewpage.action?pageId=197702790\n",
    "ds_tp = ds_tp * 1000 * 30 * 12 # Convert to yearly mm \n",
    "ds_combined = xr.merge([ds_t2m, ds_tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4347f249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shp file...\n",
      "Filtering temperature data...\n",
      "Total points within boundary: 259902\n",
      "Total points within temperature range: 257566\n",
      "Loading lakes and rivers...\n",
      "Getting elevation data...\n",
      "Total elevation points and chunks: 15151, 8\n",
      "getting elevation batch 0...\n",
      "200 OK\n",
      "getting elevation batch 1...\n",
      "200 OK\n",
      "getting elevation batch 2...\n",
      "200 OK\n",
      "getting elevation batch 3...\n",
      "200 OK\n",
      "getting elevation batch 4...\n",
      "200 OK\n",
      "getting elevation batch 5...\n",
      "200 OK\n",
      "getting elevation batch 6...\n",
      "200 OK\n",
      "getting elevation batch 7...\n",
      "200 OK\n",
      "Merging elevation data...\n"
     ]
    }
   ],
   "source": [
    "countries = [\"Kenya\",\"Ethiopia\", \"Uganda\"] #, \"United Republic of Tanzania\"]\n",
    "coffee_type = \"robusta\" # \"arabica\" or \"robusta\"\n",
    "year = [1950, 2026]\n",
    "months =  [1, 2, 3, 9, 10, 11, 12]  #Growing season # list(range(1,13)) \n",
    "end_month = \"MAR\"\n",
    "arabica_hardiness = {\n",
    "    \"optimal_temp_range\": [14, 28],\n",
    "    \"absolute_temp_range\": [10, 34],\n",
    "    \"precipitation_range\": [1500, 2000],\n",
    "    \"elevation_range\": [800, 2000]\n",
    "}\n",
    "\n",
    "robusta_hardiness = {\n",
    "    \"optimal_temp_range\": [20, 30],\n",
    "    \"absolute_temp_range\": [12, 36],\n",
    "    \"precipitation_range\": [900, 4000],\n",
    "    \"elevation_range\": [0, 800]\n",
    "}\n",
    "\n",
    "hardiness = arabica_hardiness if coffee_type == \"arabica\" else robusta_hardiness\n",
    "\n",
    "temp_range = hardiness[\"absolute_temp_range\"]\n",
    "elevation_range = hardiness[\"elevation_range\"]\n",
    "precipitation_range = hardiness[\"precipitation_range\"]\n",
    "# Growing season Done\n",
    "# October to January Done\n",
    "# Rearrange time timeframe Done\n",
    "# remove urban areas and take \n",
    "# Add elevation layer Done\n",
    "\n",
    "# Read shp file \n",
    "print(\"Loading shp file...\")\n",
    "\n",
    "boundaries = gpd.read_file(\"dataset/ne_110m_admin_0_countries/ne_110m_admin_0_countries.shp\")\n",
    "boundary = get_boundaries(boundaries, countries)\n",
    "boundary_union = boundary.union_all()\n",
    "# Get temperature data\n",
    "print(\"Filtering temperature data...\")\n",
    "temp_df = get_hardiness_zones(ds_combined, boundary_union,temp_range=temp_range, precipitation_range=precipitation_range, months=months, years=year, end_month=end_month)\n",
    "temp_df = temp_df[temp_df[\"zones\"] == 1] # Get filtered temperature data\n",
    "\n",
    "# Read lakes and rivers\n",
    "print(\"Loading lakes and rivers...\")\n",
    "lakes = gpd.read_file(\"./dataset/ne_10m_lakes/ne_10m_lakes.shp\")\n",
    "rivers = gpd.read_file(\"./dataset/ne_10m_rivers_lake_centerlines/ne_10m_rivers_lake_centerlines.shp\")\n",
    "\n",
    "lakes = lakes[lakes[\"geometry\"].intersects(boundary_union)]\n",
    "rivers = rivers[rivers[\"geometry\"].intersects(boundary_union)]\n",
    "\n",
    "temp_df = temp_df[~temp_df[\"geometry\"].intersects(lakes.union_all())]\n",
    "temp_df = temp_df[~temp_df[\"geometry\"].intersects(rivers.union_all())]\n",
    "temp_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get elevation from SRTM CGIAR Elevation Database\n",
    "print(\"Getting elevation data...\")  \n",
    "url = \"https://api.open-elevation.com/api/v1/lookup\"\n",
    "elevation_points = temp_df[[\"longitude\", \"latitude\"]].drop_duplicates()\n",
    "\n",
    "data_chunks = split_dataframe(elevation_points, split_size=2000)\n",
    "print(f\"Total elevation points and chunks: {len(elevation_points)}, {len(data_chunks)}\")\n",
    "elevation_list = []\n",
    "for i, data in enumerate(data_chunks): # [data1, data2, data3, data4]\n",
    "    print(f\"getting elevation batch {i}...\")\n",
    "    res = requests.post(url, json=data)\n",
    "    print(res.status_code, res.reason)\n",
    "    elevation = res.json()[\"results\"]\n",
    "    elevation = gpd.GeoDataFrame(elevation)\n",
    "    elevation = elevation.round(6)\n",
    "    geometry = gpd.points_from_xy(elevation.longitude, elevation.latitude)\n",
    "    elevation = elevation.set_geometry(geometry, crs=temp_df.crs)\n",
    "    elevation_list.append(elevation)\n",
    "\n",
    "print(\"Merging elevation data...\")\n",
    "elevation = gpd.pd.concat(elevation_list, ignore_index=True)\n",
    "elevation.reset_index(drop=True, inplace=True)\n",
    "temp_df = temp_df.merge(elevation[[\"elevation\", \"geometry\"]], on=\"geometry\", how=\"left\")\n",
    "temp_df = temp_df[temp_df[\"elevation\"].between(elevation_range[0], elevation_range[1])]\n",
    "temp_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # temp_df.to_file(\"filtered_temp_data.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ea1fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster hardiness zones\n",
    "clustered_hardiness_zones = cluster_temperature_data(temp_df, eps=0.115, hull_ratio=0.02)\n",
    "clustered_hardiness_zones = gpd.GeoDataFrame(clustered_hardiness_zones, crs=temp_df.crs)\n",
    "clustered_hardiness_zones[\"time\"] = gpd.pd.to_datetime(clustered_hardiness_zones[\"time\"], format=\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ef078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get area of hardiness zones\n",
    "yearly_hardiness_area = clustered_hardiness_zones.dissolve(by=\"time\", aggfunc=\"sum\")\n",
    "yearly_hardiness_area = yearly_hardiness_area.to_crs({'proj':'cea'}).area / 10**6\n",
    "# In km^2\n",
    "# yearly_hardiness_area\n",
    "yearly_hardiness_area.plot(title=\"Area of Hardiness Zones Over the Years\", ylabel=\"Area (km^2)\", xlabel=\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab87540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_hardiness_area = yearly_hardiness_area.reset_index()\n",
    "yearly_hardiness_area[\"file_name\"] = [f\"hardiness_zones_{year}.jpeg\" for year in yearly_hardiness_area[\"time\"].values]\n",
    "yearly_hardiness_area.rename(columns={0: \"area_km2\"}, inplace=True)\n",
    "yearly_hardiness_area.to_csv(f\"./results/{coffee_type}/hardiness_zones.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c199cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 1000 \n",
    "\n",
    "years = temp_df[\"time\"].dt.year.unique()\n",
    "print(years)\n",
    "print(coffee_type)\n",
    "for year in years:\n",
    "    print(year)\n",
    "    yearly_temp_df = temp_df[temp_df[\"time\"].dt.year == year]\n",
    "    yearly_temp_df.to_crs(epsg=3857, inplace=True)\n",
    "    yearly_clustered = clustered_hardiness_zones[clustered_hardiness_zones[\"time\"].dt.year == year]\n",
    "    yearly_clustered.to_crs(epsg=3857, inplace=True)\n",
    "\n",
    "    # Create custom colormap\n",
    "    ranges = [min(yearly_temp_df[\"t2m\"].min(), hardiness[\"optimal_temp_range\"][0]), \n",
    "          hardiness[\"optimal_temp_range\"][0], \n",
    "          hardiness[\"optimal_temp_range\"][1],\n",
    "          max(yearly_temp_df[\"t2m\"].max(), hardiness[\"optimal_temp_range\"][1])]\n",
    "\n",
    "    ranges_n = [(v - ranges[0]) / (ranges[-1] - ranges[0]) for v in ranges]\n",
    "    ranges_n_diff = [max(round((j - i) * n_sample), 1) for i, j in zip(ranges_n[:-1], ranges_n[1:])]\n",
    "    #print(ranges_n_diff, ranges_n, ranges)\n",
    "    # Build custom cmap\n",
    "    left_green = mpl.colormaps['Greens'].resampled(ranges_n_diff[0])\n",
    "    left_green = left_green(np.linspace(0, 1, ranges_n_diff[0]))\n",
    "\n",
    "    mid_green = np.array([left_green[-1, :]] * ranges_n_diff[1])\n",
    "\n",
    "    right_green = mpl.colormaps['Greens_r'].resampled(ranges_n_diff[2])\n",
    "    right_green = right_green(np.linspace(0, 1, ranges_n_diff[2]))\n",
    "\n",
    "    newGreen = np.vstack((left_green, mid_green, right_green))\n",
    "    customGreen = ListedColormap(newGreen, name='CustomGreen')\n",
    "\n",
    "\n",
    "    # Plot data \n",
    "    fig, ax = plt.subplots(figsize=(15, 15), dpi=200)\n",
    "    yearly_temp_df.plot(column=\"t2m\",ax=ax, markersize=15, marker=\"s\", cmap=customGreen, alpha=0.6, label=\"Temperature Points\", legend=True, legend_kwds={'label': \"temperature\", 'shrink': 0.5})\n",
    "    #yearly_clustered.plot(ax=ax, markersize=10, color=\"green\", alpha=0.4, label=\"Hardiness Zones\")\n",
    "    rivers.to_crs(epsg=3857).plot(ax=ax, color=\"blue\", alpha=0.5, label=\"Water Bodies\")\n",
    "    lakes.to_crs(epsg=3857).plot(ax=ax, color=\"blue\", alpha=0.5, label=\"Water Bodies\")\n",
    "    plt.figtext(0.025, 0.92, f\"Total Area: {yearly_hardiness_area.loc[yearly_hardiness_area.index.year == year].values[0]:.2f} km²\", fontsize=12, bbox={\"facecolor\": \"white\", \"alpha\": 0.5, \"pad\": 5})\n",
    "    \n",
    "    # Plot contour for elevation\n",
    "    #yearly_temp_df.plot(column=\"elevation\", ax=ax, markersize=3, cmap=\"BuPu\", alpha=0.9, legend=True, legend_kwds={'label': \"Elevation (m)\", 'shrink': 0.5})\n",
    "\n",
    "    # Plot total precipitation\n",
    "    #yearly_temp_df.plot(column=\"tp\", ax=ax, markersize=3, cmap=customGreen, alpha=0.9, legend=True, legend_kwds={'label': \"Total Precipitation (mm)\", 'shrink': 0.5})\n",
    "\n",
    "    # Plot boundary\n",
    "    gpd.GeoSeries(boundary).to_crs(epsg=3857).plot(ax=ax, facecolor=(\"red\", 0.125), label=\"Boundaries\", edgecolor=(\"black\", 0.8), linewidth=1.5)\n",
    "\n",
    "    # Add basemap\n",
    "    ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "    ax.set_title(f\"Hardiness Zones - {year}\", fontsize=15)\n",
    "    plt.axis(\"off\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./results/{coffee_type}/hardiness_zones_{year}.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc0a956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data for HeatMapWithTime\n",
    "time_index = temp_df[\"time\"].sort_values().astype(\"str\").unique().tolist()\n",
    "#geo_df.sort_values(by=\"time\", inplace=True)\n",
    "# Group by time, convert to [[lon, lat, value], ...]\n",
    "hardiness_zones = [\n",
    "    d[[\"geometry\", \"t2m\"]]\n",
    "    .assign(lon=lambda df: df.geometry.y, lat=lambda df: df.geometry.x)\n",
    "    .loc[:, [\"lon\", \"lat\", \"t2m\"]]\n",
    "    .values.tolist()\n",
    "    for _, d in temp_df.groupby(\"time\")\n",
    "]\n",
    "\n",
    "# total_precipitation = [\n",
    "#     d[[\"geometry\", \"tp\"]]\n",
    "#     .assign(lon=lambda df: df.geometry.y, lat=lambda df: df.geometry.x)\n",
    "#     .loc[:, [\"lon\", \"lat\", \"tp\"]]\n",
    "#     .values.tolist()\n",
    "#     for _, d in temp_df.groupby(\"time\")\n",
    "# ]\n",
    "\n",
    "# elevation = [\n",
    "#     d[[\"geometry\", \"elevation\"]]\n",
    "#     .assign(lon=lambda df: df.geometry.y, lat=lambda df: df.geometry.x)\n",
    "#     .loc[:, [\"lon\", \"lat\", \"elevation\"]]\n",
    "#     .values.tolist()\n",
    "#     for _, d in temp_df.groupby(\"time\")\n",
    "# ]\n",
    "\n",
    "\n",
    "map = folium.Map(location=[9.14, 40.48], tiles=\"OpenStreetMap\", zoom_start=5, control_scale=True) # OpenStreeMap. 'cartodbpositron', stamentoner\n",
    "HeatMapWithTime(\n",
    "    hardiness_zones,\n",
    "    name=\"Hardiness Zones\",\n",
    "    index=time_index,\n",
    "    use_local_extrema=True, \n",
    "    max_opacity=0.5,\n",
    "    radius=10,\n",
    "    \n",
    ").add_to(map)\n",
    "\n",
    "# HeatMapWithTime(\n",
    "#     total_precipitation,\n",
    "#     name=\"Total Precipitation\",\n",
    "#     index=time_index,\n",
    "#     use_local_extrema=True, \n",
    "#     max_opacity=0.5,\n",
    "#     radius=10,\n",
    "#     show=False\n",
    "    \n",
    "# ).add_to(map)\n",
    "\n",
    "# HeatMapWithTime(\n",
    "#     elevation,\n",
    "#     name=\"Elevation\",\n",
    "#     index=time_index,\n",
    "#     use_local_extrema=True, \n",
    "#     max_opacity=0.5,\n",
    "#     radius=10,\n",
    "#     show=False\n",
    "# ).add_to(map)\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "map.save(\"map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef5f0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster data\n",
    "year = 2025\n",
    "yearly_temp_df = temp_df[temp_df[\"time\"].dt.year == year]\n",
    "yearly_clustered = clustered_hardiness_zones[clustered_hardiness_zones[\"time\"].dt.year == year]\n",
    "\n",
    "\n",
    "map = folium.Map(location=[8, 40], \n",
    "                 tiles=\"OpenStreetMap\", \n",
    "                 zoom_start=5,\n",
    "                 min_zoom=4,\n",
    "                 #control_scale=True,\n",
    "                 ) \n",
    "\n",
    "# Add red boundary\n",
    "boundary_geojson = gpd.GeoDataFrame({'geometry': [boundary_union]}, crs=\"EPSG:4326\")\n",
    "boundary_json = boundary_geojson.to_json()\n",
    "folium.GeoJson(\n",
    "    boundary_json,\n",
    "    name=f'{countries}',\n",
    "    style_function=lambda x: {\n",
    "        'fillColor': 'red',  # Keep red fill\n",
    "        'color': 'red',\n",
    "        'weight': 2,\n",
    "        'opacity': 0.1,  # Lower opacity so heatmap shows through\n",
    "        'fillOpacity': 0.1\n",
    "    }\n",
    ").add_to(map)\n",
    "\n",
    "# Hardiness zones\n",
    "folium.GeoJson(\n",
    "    yearly_clustered[[\"geometry\"]], \n",
    "    name=\"Hardiness Zones\", \n",
    "    marker=folium.Circle(radius=0.5, color=\"green\"),\n",
    "    style_function=lambda x: {\n",
    "        \"color\": \"green\",\n",
    "        'opacity': 0.5,  # Lower opacity so heatmap shows through\n",
    "    }\n",
    ").add_to(map)\n",
    "\n",
    "\n",
    "# # hardiness points\n",
    "# folium.GeoJson(\n",
    "#     yearly_temp_df[[\"geometry\"]], \n",
    "#     name=\"Hardiness Zones\", \n",
    "#     marker=folium.Circle(radius=0.1, color=\"green\"), \n",
    "#     style_function=lambda x: {\n",
    "#         'opacity': 0.3,  # Lower opacity so heatmap shows through\n",
    "#     }\n",
    "\n",
    "# ).add_to(map)\n",
    "\n",
    "\n",
    "# # Timeline hardiness zones\n",
    "# styledict = {}\n",
    "\n",
    "# on = {\n",
    "#     \"color\": \"green\",\n",
    "#     \"opacity\": 0.4,\n",
    "# } \n",
    "\n",
    "# off = {\n",
    "#     \"color\": \"blue\",\n",
    "#     \"opacity\": 0,\n",
    "# }\n",
    "\n",
    "# clustered_hardiness_zones[\"elapse_time\"] = clustered_hardiness_zones.time.astype(\"int64\") // 10 ** 9  \n",
    "# final_year = clustered_hardiness_zones[\"elapse_time\"].max()\n",
    "\n",
    "# for idx, data in clustered_hardiness_zones.iterrows(): \n",
    "#     styledict[str(idx)] = {\n",
    "#         #data.elapse_time - 31536000: off,\n",
    "#         data.elapse_time-1: off,\n",
    "#         data.elapse_time: on,\n",
    "#         data.elapse_time+1: off,\n",
    "#     }\n",
    "\n",
    "# TimeSliderChoropleth(\n",
    "#     clustered_hardiness_zones[\"geometry\"].to_json(),\n",
    "#     date_options=\"YYYY\",\n",
    "#     styledict=styledict,\n",
    "#     stroke_opacity=0,\n",
    "#     overlay=True,\n",
    "# ).add_to(map)\n",
    "\n",
    "\n",
    "# Add title \n",
    "map_title = f\"Hardiness Zones Map - {year}\"\n",
    "title_html = f'<h1 style=\"position:absolute;z-index:100000;left:40vw\" >{map_title}</h1>'\n",
    "map.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "map.save(\"map.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd0ad7f",
   "metadata": {},
   "source": [
    "### Load and Cluster Farmlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a429f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(3193 bytes read)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\http\\client.py:579\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_next_chunk_size()\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\http\\client.py:546\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(line, \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;66;03m# close the connection as protocol synchronisation is\u001b[39;00m\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;66;03m# probably lost\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 16: b''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\http\\client.py:595\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_chunk_left()) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_left:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\http\\client.py:581\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# last chunk: 1*(\"0\") [ chunk-extension ] CRLF\u001b[39;00m\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m api \u001b[38;5;241m=\u001b[39m overpy\u001b[38;5;241m.\u001b[39mOverpass()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Ask the client to return GeoJSON directly\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m res \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mquery(query)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\overpy\\__init__.py:138\u001b[0m, in \u001b[0;36mOverpass.query\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m    136\u001b[0m response \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunk_size)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m     data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunk_size)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[1;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_chunked(amt)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\http\\client.py:607\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(value)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(value)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(3193 bytes read)"
     ]
    }
   ],
   "source": [
    "# query = \"\"\"\n",
    "# area[\"ISO3166-1\"=\"KE\"]->.ke;\n",
    "# area[\"ISO3166-1\"=\"ET\"]->.et;\n",
    "# area[\"ISO3166-1\"=\"UG\"]->.ug;\n",
    "\n",
    "# (\n",
    "#   way(area.ke)[landuse~\"plantation|forest|farmland\"];\n",
    "#   way(area.et)[landuse~\"plantation|forest|farmland\"];\n",
    "#   way(area.ug)[landuse~\"plantation|forest|farmland\"];\n",
    "# );\n",
    "# out geom;\n",
    "# \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "[out:json][timeout:1800];\n",
    "\n",
    "// Define country relations\n",
    "rel[\"ISO3166-1\"=\"KE\"]->.rKE;\n",
    "rel[\"ISO3166-1\"=\"ET\"]->.rET;\n",
    "rel[\"ISO3166-1\"=\"UG\"]->.rUG;\n",
    "\n",
    "(.rKE; .rET; .rUG;)->.rels;\n",
    ".rels map_to_area -> .countries;\n",
    "\n",
    "// Query farmland\n",
    "(\n",
    "  way[\"landuse\"=\"farmland\"](area.countries);\n",
    "  relation[\"landuse\"=\"farmland\"](area.countries);\n",
    ");\n",
    "out body;\n",
    ">;\n",
    "out skel qt;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "api = overpy.Overpass()\n",
    "# Ask the client to return GeoJSON directly\n",
    "res = api.query(query)\n",
    "print(res)\n",
    "\n",
    "\n",
    "# # Save to GeoJSON\n",
    "# out_path = \"./dataset/landuse_ke_et_ug.geojson\"\n",
    "# with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(res, f, ensure_ascii=False)\n",
    "\n",
    "# print(f\"Saved: {out_path} | Features: {len(res.get('features', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fde13c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenya_farmlands = gpd.read_file(\"./dataset/farmland/kenya.geojson\")\n",
    "uganda_farmlands = gpd.read_file(\"./dataset/farmland/uganda.geojson\")\n",
    "ethiopia_farmlands = gpd.read_file(\"./dataset/farmland/ethiopia.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "boundaries[boundaries[\"ADMIN\"] == \"Kenya\"].plot(ax=ax, alpha=0.5)\n",
    "# gpd.GeoSeries(boundary).plot(ax=ax, cmap=\"tab20b\", alpha=0.5)\n",
    "farmlands.plot(ax=ax, color=\"green\", alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0012738",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[8, 40], \n",
    "                 tiles=\"OpenStreetMap\", \n",
    "                 zoom_start=5,\n",
    "                 min_zoom=4,\n",
    "                 #control_scale=True,\n",
    "                 ) \n",
    "\n",
    "folium.GeoJson(\n",
    "    kenya_farmlands[[\"geometry\"]], \n",
    "    name=\"Kenya Farmlands\", \n",
    "    marker=folium.Circle(radius=0.5, color=\"green\"),\n",
    "    style_function=lambda x: {\n",
    "        \"color\": \"green\",\n",
    "        'opacity': 1,  # Lower opacity so heatmap shows through\n",
    "    }\n",
    ").add_to(map)\n",
    "\n",
    "\n",
    "folium.GeoJson(\n",
    "    uganda_farmlands[[\"geometry\"]], \n",
    "    name=\"Uganda Farmlands\", \n",
    "    marker=folium.Circle(radius=0.5, color=\"green\"),\n",
    "    style_function=lambda x: {\n",
    "        \"color\": \"green\",\n",
    "        'opacity': 1,  # Lower opacity so heatmap shows through\n",
    "    }\n",
    ").add_to(map)\n",
    "\n",
    "\n",
    "folium.GeoJson(\n",
    "    ethiopia_farmlands[[\"geometry\"]], \n",
    "    name=\"Ethiopia Farmlands\", \n",
    "    marker=folium.Circle(radius=0.5, color=\"green\"),\n",
    "    style_function=lambda x: {\n",
    "        \"color\": \"green\",\n",
    "        'opacity': 1,  # Lower opacity so heatmap shows through\n",
    "    }\n",
    ").add_to(map)\n",
    "\n",
    "map.save(\"farmlands_map.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431dd31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
